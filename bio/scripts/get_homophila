#!/usr/bin/perl

# script to download the latest homophila release into a directory like
# homophila/2.1
# the version used in the directory name is the version mentioned on the Homophila web page
# the script should be run in /shared/data
# modified by Philip North 20/03/07 to include parts of the process that were previously done manually

use strict;
use warnings;

use IO::All;
BEGIN {
  # find the lib directory by looking at the path to this script
  push (@INC, ($0 =~ m:(.*)/.*:)[0] . '/../../intermine/perl/lib/');
}
use InterMine::DataDownloader;

#homophila source directories and files
my $homophila_server = "http://superfly.ucsd.edu/homophila";
my $homophila_data_file = "homophila_all.txt";
my $homophila_matches_file = "homophila_matches.txt";
my $homophila_diseases_file = "homophila_diseases.txt";
my $protein_ids_file = "protein_ids.txt";

#flymine destination directories and files
my $homophila_main_dir = "/shared/data/homophila";
my $temp_dir = "$homophila_main_dir/temp";
my $temp_file = "$temp_dir/temp.txt";
my $file_to_get = "$homophila_server/$homophila_data_file.gz";
my $date = &convert_date();
my $data_dir = "$homophila_main_dir/$date";
my $data_file = "$data_dir/$homophila_data_file";

#make sure that the necessary directories exist and download the file
&checkdir_exists($homophila_main_dir);
&checkdir_exists($temp_dir);
&http_download($file_to_get,"$temp_file.gz");
&unzip_dir($temp_dir);

#compare the files, create version directory if it is a new version or
#the current data link is missing
my $current_link = "/shared/data/homophila/current";
my $old_file = "$current_link/homophila_all.txt";

my $result = &compare_files($old_file,$temp_file);
if($result == 1){
	print "Keeping downloaded files.\n";
	&checkdir_exists($data_dir);
	system("mv $temp_file $data_file");
	&make_link($date,$current_link);
}elsif($result == 0 ){
	unlink $temp_file;
	print "Downloaded files deleted.\n";
	$data_dir = $current_link;
}

#create the diseases and matches file and the hash needed to query Entrez
my $matches = "$data_dir/$homophila_matches_file";
my $diseases = "$data_dir/$homophila_diseases_file";
my $prots = "$data_dir/$protein_ids_file";

if( (-e $matches)&&(-e $diseases)&&(-e $prots) ){
	warn "Homophila dieseases and matches files already generated\n";
}else{
	#process the downloaded file
	open HOMOPHILA_DATA, "$data_file"
	  or die "can't open $data_file\n";

	my $line = <HOMOPHILA_DATA>;
	if ($line !~ /CG\tOMIM_ID/) {
	  die "expected first line of $data_file to be a header\n";
	}
	my %homophila_matches = ();
	my %homophila_diseases = ();
	my %proteinID = ();
	
	while ($line = <HOMOPHILA_DATA>) {
		chomp $line;
		my @bits = split /\t/, $line;
	
		#get unique matches and diseases
		$homophila_matches{join "\t", @bits[0..3]}++;
		if(@bits[1,6]){
			$homophila_diseases{join "\t", @bits[1,6]}++;
		}
		#and protein Ids
		$proteinID{$bits[2]} = $bits[2];
	}
	close HOMOPHILA_DATA;

	#write processed data to file
	print "Writing files.\n";
	&print_hash2file($matches,%homophila_matches);
	&print_hash2file($diseases,%homophila_diseases);
	&print_hash2file($prots,%proteinID);
}

#print file
sub print_hash2file{
my ($file, %hash) = @_;

open FH, ">$file"
   or die "can't open $file\n";
for my $line (sort keys %hash) {
  print FH "$line\n";
}
close FH;
}

#===================================================================================
# this part replaces the manual batch upload of protein ids to ncbi entrez
# uses eutils to access ncbi with the protein Ids and retrieve the GenPept entries.

use LWP::Simple;

# output file
my $sequences_file = "$data_dir/sequences.gp";

# eutils URL
my $utils = "http://www.ncbi.nlm.nih.gov/entrez/eutils";

# define database and output format
my $db     = "Protein";
my $report = "gp";

if(-e $sequences_file){
	warn "sequences.gp already generated\n";
}else{
	print "Querying NCBI Entrez and writing sequences.gp\n";
	# URL for esearch
	my $esearch = "$utils/esearch.fcgi?" .
	              "db=$db&retmax=1&usehistory=y&term=";

	open SEQUENCES, ">$sequences_file"
	   or die "can't open $sequences_file\n";
	
	open(PROT, "<$prots") or die "$!";
	while (my $queryID = <PROT>) {
		chomp $queryID;
		# id to be queried by esearch and final esearch URL
		#print "Query ID $queryID\n";
		my $esearch_result = get($esearch . $queryID);
	
		# identify parameters for efetch
		$esearch_result =~
		  m|<Count>(\d+)</Count>.*<QueryKey>(\d+)</QueryKey>.*<WebEnv>(\S+)</WebEnv>|s;

		my $Count    = $1;
		my $QueryKey = $2;
		my $WebEnv   = $3;
		#print "Count = $Count; QueryKey = $QueryKey; WebEnv = $WebEnv\n\n";

		my $retstart;
		my $retmax=3;
	
		# for each record found by esearch, use efetch to retrieve it
		for($retstart = 0; $retstart < $Count; $retstart += $retmax) {
			my $efetch = "$utils/efetch.fcgi?"."rettype=$report&retmode=text&retstart=$retstart&retmax=$retmax&" .
		  	            "db=$db&query_key=$QueryKey&WebEnv=$WebEnv";     
			my $efetch_result = get($efetch);
	  		print SEQUENCES "$efetch_result\n";		
		}
		&delay();
	}close SEQUENCES;
}
# implements the three second delay between queries as required by ncbi
sub delay(){
my $future = (time + 3);
	while (1) {
    	if (time >= $future) {
   	    	return;        
   		}
	}
}
#=================================================================================
# this part was once create_protein_gene.pl 

# output file
my $prot_gene_file = "$data_dir/protein_gene.txt";
my $more = 0;
my $cds = 0;

if(-e $prot_gene_file){
	warn "protein_gene.txt already generated\n";
}else{
	print "Writing protein_gene.txt\n";

	open PROT_GENES, ">$prot_gene_file"
	   or die "can't open $prot_gene_file\n";

	open(FILE, "<$sequences_file") or die "$!";
	while (<FILE>) {
		if (!$more && /LOCUS      /) {
	    	$more = 1;
	  	}
		if( $more && (/(NP_\d+)/ || /(XP_\d+)/) ){
	    	print PROT_GENES "$1\t";
	    	$more = 0;
	    	$cds = 0;
		}
		if (!$cds && /CDS      /) {
	    	$cds = 1;
  		}
		if ($cds && /gene="(.+)"/) {
    		if ($more) { print "|"; }
    		print PROT_GENES "$1\n";
   			$more = 1;
  		}	
	}
	close (FILE) or die "$!";
	close PROT_GENES;
}
